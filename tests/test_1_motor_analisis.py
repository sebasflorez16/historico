#!/usr/bin/env python
"""
Test Completo del Motor de An√°lisis Agr√≠cola Profesional v2.0
==============================================================

Prueba todas las funcionalidades del motor mejorado:
1. Procesamiento raster avanzado
2. An√°lisis de series temporales
3. Detecci√≥n de cambios estructurales
4. Predicci√≥n de tendencias
5. Exportaci√≥n para dashboards

Ejecutar:
    python tests/test_motor_completo_v2.py
"""

import os
import sys
import django
from datetime import datetime, timedelta
import numpy as np
import logging

# Configurar Django
base_dir = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
sys.path.insert(0, base_dir)
os.environ.setdefault('DJANGO_SETTINGS_MODULE', 'historical.settings')
django.setup()

# Importar motor
from informes.motor_analisis import (
    procesador_raster,
    analizador_series,
    exportador,
    GeneradorDiagnosticos
)

logging.basicConfig(level=logging.INFO, format='%(levelname)s: %(message)s')
logger = logging.getLogger(__name__)


def generar_datos_sinteticos():
    """Genera datos sint√©ticos realistas para pruebas"""
    logger.info("=" * 80)
    logger.info("üìä GENERANDO DATOS SINT√âTICOS DE PARCELA")
    logger.info("=" * 80)
    
    # Serie temporal de 24 meses con tendencia y estacionalidad
    fechas = [datetime(2023, 1, 1) + timedelta(days=30*i) for i in range(24)]
    
    # Tendencia: ligera mejora (0.5 ‚Üí 0.65)
    tendencia = np.linspace(0.5, 0.65, 24)
    
    # Estacionalidad: ciclo anual (m√°ximo en verano, m√≠nimo en invierno)
    estacionalidad = 0.1 * np.sin(np.linspace(0, 4*np.pi, 24))
    
    # Ruido: variaciones aleatorias
    np.random.seed(42)
    ruido = np.random.normal(0, 0.03, 24)
    
    # Anomal√≠a simulada (sequ√≠a en mes 10)
    anomalia = np.zeros(24)
    anomalia[10:13] = -0.15
    
    # Serie completa
    ndvi = tendencia + estacionalidad + ruido + anomalia
    ndvi = np.clip(ndvi, 0, 1)  # Mantener en rango v√°lido
    
    # Generar arrays 2D simulando imagen raster (100x100 pixels)
    raster_actual = np.random.normal(ndvi[-1], 0.05, (100, 100))
    raster_actual = np.clip(raster_actual, 0, 1)
    
    logger.info(f"‚úÖ Generados {len(fechas)} puntos temporales")
    logger.info(f"‚úÖ Raster simulado: {raster_actual.shape} pixels")
    logger.info(f"   NDVI actual: {ndvi[-1]:.3f}")
    logger.info(f"   NDVI promedio hist√≥rico: {np.mean(ndvi):.3f}")
    
    return {
        'fechas': fechas,
        'ndvi': ndvi.tolist(),
        'raster_actual': raster_actual,
        'area_hectareas': 50.5
    }


def test_procesador_raster(datos):
    """Prueba procesador raster avanzado"""
    logger.info("\n" + "=" * 80)
    logger.info("üî¨ TEST 1: PROCESADOR RASTER AVANZADO")
    logger.info("=" * 80)
    
    raster = datos['raster_actual']
    area = datos['area_hectareas']
    
    # 1. Estad√≠sticas zonales
    logger.info("\nüìä Calculando estad√≠sticas zonales...")
    stats = procesador_raster.calcular_estadisticas_zonales(
        valores_array=raster.flatten(),
        area_hectareas=area,
        num_bins=10
    )
    logger.info(f"   Media: {stats.media:.4f}")
    logger.info(f"   Desviaci√≥n est√°ndar: {stats.desviacion:.4f}")
    logger.info(f"   Coeficiente de variaci√≥n: {stats.coef_variacion:.2f}%")
    logger.info(f"   Rango: [{stats.minimo:.4f}, {stats.maximo:.4f}]")
    
    # 2. Detecci√≥n de hotspots
    logger.info("\nüî• Detectando hotspots y coldspots...")
    hotspots = procesador_raster.detectar_hotspots(
        valores_array=raster.flatten(),
        umbral_percentil=90
    )
    logger.info(f"   Umbral alto (P90): {hotspots['umbral_alto']:.4f}")
    logger.info(f"   Umbral bajo (P10): {hotspots['umbral_bajo']:.4f}")
    logger.info(f"   Hotspots positivos: {hotspots['num_hotspots_positivos']} "
                f"({hotspots['porcentaje_positivo']:.1f}%)")
    logger.info(f"   Hotspots negativos: {hotspots['num_hotspots_negativos']} "
                f"({hotspots['porcentaje_negativo']:.1f}%)")
    logger.info(f"   ‚û°Ô∏è  {hotspots['interpretacion']}")
    
    # 3. An√°lisis de calidad
    logger.info("\n‚úÖ Analizando calidad de imagen...")
    calidad = procesador_raster.analizar_calidad_imagen(
        valores_array=raster.flatten(),
        nubosidad=5.0
    )
    logger.info(f"   P√≠xeles v√°lidos: {calidad['pixels_validos']}/{calidad['total_pixels']} "
                f"({calidad['porcentaje_validos']:.1f}%)")
    logger.info(f"   Calidad: {calidad['calidad']} (confianza {calidad['confianza']})")
    logger.info(f"   ‚û°Ô∏è  {calidad['recomendacion']}")
    
    # 4. Variabilidad espacial
    logger.info("\nüìê Calculando variabilidad espacial...")
    variabilidad = procesador_raster.calcular_variabilidad_espacial(
        valores_array=raster.flatten(),
        metodo='all'
    )
    logger.info(f"   Coeficiente de variaci√≥n: {variabilidad['coef_variacion']}%")
    logger.info(f"   ‚û°Ô∏è  {variabilidad['interpretacion_cv']}")
    logger.info(f"   Rango intercuart√≠lico: {variabilidad['iqr']:.4f}")
    logger.info(f"   ‚û°Ô∏è  {variabilidad['interpretacion_iqr']}")
    logger.info(f"   Entrop√≠a Shannon: {variabilidad['entropia']:.4f}")
    logger.info(f"   ‚û°Ô∏è  {variabilidad['interpretacion_entropia']}")
    
    return {
        'estadisticas': stats.to_dict(),
        'hotspots': hotspots,
        'calidad': calidad,
        'variabilidad': variabilidad
    }


def test_analizador_series_temporal(datos):
    """Prueba analizador de series temporales"""
    logger.info("\n" + "=" * 80)
    logger.info("üìà TEST 2: AN√ÅLISIS DE SERIES TEMPORALES")
    logger.info("=" * 80)
    
    fechas = datos['fechas']
    valores = datos['ndvi']
    
    # 1. Descomposici√≥n de serie
    logger.info("\nüîç Descomponiendo serie temporal...")
    descomp = analizador_series.descomponer_serie(
        valores=valores,
        fechas=fechas,
        periodo=12
    )
    logger.info(f"   Tendencia media: {np.mean(descomp.tendencia):.4f}")
    logger.info(f"   Amplitud estacional: {np.std(descomp.estacionalidad):.4f}")
    logger.info(f"   Ruido (std residuos): {np.std(descomp.residuos):.4f}")
    
    # 2. Detecci√≥n de puntos de cambio
    logger.info("\n‚ö° Detectando puntos de cambio estructural...")
    cambios = analizador_series.detectar_puntos_cambio(
        valores=valores,
        fechas=fechas,
        umbral_cambio=0.10
    )
    if cambios.indices:
        logger.info(f"   Detectados {len(cambios.indices)} puntos de cambio:")
        for i, (fecha, antes, despues, mag, sig) in enumerate(zip(
            cambios.fechas, cambios.valores_antes, cambios.valores_despues,
            cambios.magnitud_cambio, cambios.significancia
        )):
            logger.info(f"   {i+1}. {fecha.strftime('%Y-%m-%d')}: "
                       f"{antes:.3f} ‚Üí {despues:.3f} "
                       f"(Œî={mag:.3f}, significancia={sig})")
    else:
        logger.info("   No se detectaron cambios estructurales significativos")
    
    # 3. Predicci√≥n de tendencias
    logger.info("\nüîÆ Prediciendo tendencia futura...")
    prediccion = analizador_series.predecir_tendencia(
        valores=valores,
        fechas=fechas,
        meses_futuro=3,
        grado_polinomio=2
    )
    if 'error' not in prediccion:
        logger.info(f"   R¬≤ del modelo: {prediccion['r_cuadrado']:.4f}")
        logger.info(f"   Confianza: {prediccion['confianza']}")
        logger.info(f"   Predicciones:")
        for fecha, valor in zip(prediccion['fechas_futuras'], prediccion['valores_predichos']):
            logger.info(f"      {fecha[:10]}: NDVI = {valor:.3f}")
        logger.info(f"   ‚û°Ô∏è  {prediccion['interpretacion']}")
    
    # 4. Autocorrelaci√≥n
    logger.info("\nüîÑ Analizando autocorrelaci√≥n...")
    autocorr = analizador_series.calcular_autocorrelacion(
        valores=valores,
        max_lag=12
    )
    if 'error' not in autocorr:
        logger.info(f"   Lag de m√°xima correlaci√≥n: {autocorr['lag_max_correlacion']} meses")
        logger.info(f"   Correlaci√≥n m√°xima: {autocorr['max_correlacion']:.4f}")
        logger.info(f"   ‚û°Ô∏è  {autocorr['interpretacion']}")
    
    return {
        'descomposicion': descomp.to_dict(),
        'cambios': cambios.to_dict(),
        'prediccion': prediccion,
        'autocorrelacion': autocorr
    }


def test_exportador(datos, analisis_raster, analisis_temporal):
    """Prueba exportador de resultados"""
    logger.info("\n" + "=" * 80)
    logger.info("üíæ TEST 3: EXPORTADOR DE RESULTADOS")
    logger.info("=" * 80)
    
    # 1. Exportar serie temporal
    logger.info("\nüìä Exportando serie temporal...")
    serie_export = exportador.exportar_serie_temporal(
        serie_datos=[
            {'fecha': f, 'media': v, 'minimo': v-0.05, 'maximo': v+0.05,
             'percentil_25': v-0.02, 'percentil_75': v+0.02}
            for f, v in zip(datos['fechas'], datos['ndvi'])
        ],
        tipo_indice='ndvi'
    )
    logger.info(f"   ‚úÖ Serie exportada: {serie_export['metadata']['num_puntos']} puntos")
    logger.info(f"   Per√≠odo: {serie_export['metadata']['fecha_inicio'][:10]} ‚Üí "
               f"{serie_export['metadata']['fecha_fin'][:10]}")
    logger.info(f"   Rango valores: [{serie_export['metadata']['rango_valores']['min']:.3f}, "
               f"{serie_export['metadata']['rango_valores']['max']:.3f}]")
    
    # 2. Exportar alertas como timeline
    logger.info("\n‚è±Ô∏è  Generando timeline de eventos...")
    eventos = []
    if analisis_temporal['cambios']['indices']:
        for i, (fecha, mag, sig) in enumerate(zip(
            analisis_temporal['cambios']['fechas'],
            analisis_temporal['cambios']['magnitud_cambio'],
            analisis_temporal['cambios']['significancia']
        )):
            eventos.append({
                'id': f'cambio_{i}',
                'fecha': datetime.fromisoformat(fecha),
                'descripcion': f'Cambio estructural (Œî={mag:.3f})',
                'tipo': 'point',
                'categoria': 'cambio',
                'severidad': 'alto' if sig == 'alta' else 'medio',
                'detalle': f'Cambio de magnitud {mag:.3f} con significancia {sig}'
            })
    
    timeline = exportador.exportar_timeline(eventos)
    logger.info(f"   ‚úÖ Timeline generado: {len(timeline)} eventos")
    for evento in timeline[:3]:  # Mostrar primeros 3
        logger.info(f"   ‚Ä¢ {evento['start'][:10]}: {evento['content']}")
    
    # 3. Dashboard completo
    logger.info("\nüì± Generando dashboard completo...")
    dashboard = exportador.exportar_dashboard_completo(
        analisis_completo={
            'estado_general': 'Bueno',
            'tendencia': 'Mejorando',
            'num_alertas': len(eventos),
            'metricas_clave': {
                'ndvi_actual': datos['ndvi'][-1],
                'ndvi_promedio': np.mean(datos['ndvi']),
                'cv': analisis_raster['variabilidad']['coef_variacion']
            },
            'serie_ndvi': [
                {'fecha': f, 'media': v}
                for f, v in zip(datos['fechas'], datos['ndvi'])
            ],
            'alertas': eventos,
            'zonificacion': analisis_raster['hotspots'],
            'recomendaciones': [
                'Mantener pr√°cticas actuales de riego',
                'Monitorear zonas de bajo vigor (hotspots negativos)',
                'Planificar fertilizaci√≥n para pr√≥ximo per√≠odo'
            ]
        },
        incluir_geometrias=False
    )
    logger.info(f"   ‚úÖ Dashboard generado con {len(dashboard.keys())} secciones")
    logger.info(f"   ‚Ä¢ Resumen ejecutivo: {dashboard['resumen_ejecutivo']}")
    logger.info(f"   ‚Ä¢ Series temporales: {len(dashboard['series_temporales'])} √≠ndices")
    logger.info(f"   ‚Ä¢ Alertas: {len(dashboard['alertas'])} eventos")
    logger.info(f"   ‚Ä¢ Recomendaciones: {len(dashboard['recomendaciones'])} items")
    
    # 4. Guardar JSON
    import tempfile
    archivo_json = os.path.join(tempfile.gettempdir(), 'dashboard_agrotech.json')
    exportador.guardar_json(dashboard, archivo_json, pretty=True)
    logger.info(f"\nüíæ Dashboard guardado en: {archivo_json}")
    
    # Mostrar tama√±o
    tamanio_kb = os.path.getsize(archivo_json) / 1024
    logger.info(f"   Tama√±o: {tamanio_kb:.1f} KB")
    
    return {
        'serie': serie_export,
        'timeline': timeline,
        'dashboard': dashboard,
        'archivo_json': archivo_json
    }


def test_integracion_completa():
    """Test de integraci√≥n completa del motor"""
    logger.info("\n" + "=" * 80)
    logger.info("üöÄ TEST 4: INTEGRACI√ìN COMPLETA")
    logger.info("=" * 80)
    
    # Generar datos
    datos = generar_datos_sinteticos()
    
    # Ejecutar todos los an√°lisis
    logger.info("\nüîÑ Ejecutando pipeline completo de an√°lisis...")
    
    # Test 1: Raster
    analisis_raster = test_procesador_raster(datos)
    
    # Test 2: Series temporales
    analisis_temporal = test_analizador_series_temporal(datos)
    
    # Test 3: Exportaci√≥n
    exportacion = test_exportador(datos, analisis_raster, analisis_temporal)
    
    # Resumen final
    logger.info("\n" + "=" * 80)
    logger.info("üìã RESUMEN FINAL DE AN√ÅLISIS")
    logger.info("=" * 80)
    
    logger.info("\n‚úÖ ESTADO GENERAL: BUENO")
    logger.info(f"   NDVI actual: {datos['ndvi'][-1]:.3f}")
    logger.info(f"   NDVI promedio hist√≥rico: {np.mean(datos['ndvi']):.3f}")
    logger.info(f"   Tendencia: {'Mejorando' if datos['ndvi'][-1] > np.mean(datos['ndvi']) else 'Deteriorando'}")
    
    logger.info("\nüìä M√âTRICAS CLAVE:")
    logger.info(f"   ‚Ä¢ Variabilidad espacial: {analisis_raster['variabilidad']['coef_variacion']}%")
    logger.info(f"   ‚Ä¢ Calidad de imagen: {analisis_raster['calidad']['calidad']}")
    logger.info(f"   ‚Ä¢ Puntos de cambio detectados: {len(analisis_temporal['cambios']['indices'])}")
    logger.info(f"   ‚Ä¢ Confianza predicci√≥n: {analisis_temporal['prediccion'].get('confianza', 'N/A')}")
    
    logger.info("\nüéØ RECOMENDACIONES:")
    logger.info("   1. Mantener monitoreo regular de √≠ndices vegetativos")
    logger.info("   2. Prestar atenci√≥n a hotspots negativos (zonas de estr√©s)")
    logger.info("   3. Validar tendencia proyectada con observaciones de campo")
    logger.info("   4. Considerar an√°lisis de alta resoluci√≥n en zonas cr√≠ticas")
    
    logger.info("\n" + "=" * 80)
    logger.info("‚úÖ TODOS LOS TESTS COMPLETADOS EXITOSAMENTE")
    logger.info("=" * 80)
    logger.info(f"\nüí° Motor de An√°lisis Agr√≠cola v2.0 - 100% Funcional")
    logger.info(f"   ‚Ä¢ Sin dependencias de IA externa")
    logger.info(f"   ‚Ä¢ An√°lisis reproducible y auditable")
    logger.info(f"   ‚Ä¢ Exportaci√≥n lista para dashboards")
    logger.info(f"   ‚Ä¢ Soporte completo para geoprocesamiento")
    logger.info("\n")


if __name__ == '__main__':
    try:
        test_integracion_completa()
    except Exception as e:
        logger.error(f"‚ùå Error en test: {str(e)}")
        import traceback
        traceback.print_exc()
        sys.exit(1)
